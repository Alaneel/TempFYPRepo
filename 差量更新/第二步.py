import requests
import json
import time
import os
from loguru import logger
import re
from func_timeout import func_set_timeout
import urllib3

urllib3.disable_warnings()
import sqlite3
import pandas as pd
from datetime import datetime, timedelta

logger.add("logs/propertyguru_2_incremental.log", level="INFO")


class propertyguru:

    def __init__(self):
        self.apikey = ''
        self.proxy = ''
        self.data_dir = "data"
        self.html_dir = os.path.join(self.data_dir, "html")
        self.json_dir = os.path.join(self.data_dir, "json")

        os.makedirs(self.html_dir, exist_ok=True)
        os.makedirs(self.json_dir, exist_ok=True)
        os.makedirs(self.data_dir, exist_ok=True)

        self.db_path = os.path.join(self.data_dir, "propertyguru_2.db")

        # ä»£ç†ä¿¡æ¯è¿‡æœŸæ—¶é—´ï¼ˆå¤©æ•°ï¼‰
        self.AGENT_INFO_EXPIRY_DAYS = 90  # 90å¤©åé‡æ–°è·å–

        # æœ€å¤§é‡è¯•æ¬¡æ•°
        self.MAX_RETRIES = 3

        self.init_database()

    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“ï¼Œåˆ›å»ºè¡¨ç»“æ„"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # ä¸»æ•°æ®è¡¨
            cursor.execute('''
                           CREATE TABLE IF NOT EXISTS propertyguru
                           (
                               ID
                               TEXT,
                               localizedTitle
                               TEXT,
                               fullAddress
                               TEXT,
                               price_pretty
                               TEXT,
                               beds
                               TEXT,
                               baths
                               TEXT,
                               area_sqft
                               TEXT,
                               price_psf
                               TEXT,
                               nearbyText
                               TEXT,
                               built_year
                               TEXT,
                               property_type
                               TEXT,
                               tenure
                               TEXT,
                               url_path
                               TEXT
                               PRIMARY
                               KEY,
                               recency_text
                               TEXT,
                               agent_id
                               TEXT,
                               agent_name
                               TEXT,
                               agent_description
                               TEXT,
                               agent_url_path
                               TEXT,
                               CEA
                               TEXT,
                               mobile
                               TEXT,
                               rating
                               TEXT,
                               buy_rent
                               TEXT,
                               created_at
                               TIMESTAMP
                               DEFAULT
                               CURRENT_TIMESTAMP,
                               updated_at
                               TIMESTAMP
                               DEFAULT
                               CURRENT_TIMESTAMP
                           )
                           ''')

            # çˆ¬è™«è®°å½•è¡¨ï¼ˆå¢å¼ºç‰ˆï¼‰
            cursor.execute('''
                           CREATE TABLE IF NOT EXISTS propertyguru_spider
                           (
                               url_path
                               TEXT
                               PRIMARY
                               KEY,
                               status
                               TEXT,
                               retry_count
                               INTEGER
                               DEFAULT
                               0,
                               last_error
                               TEXT,
                               crawled_at
                               TIMESTAMP
                               DEFAULT
                               CURRENT_TIMESTAMP
                           )
                           ''')

            # å¤±è´¥è®°å½•è¡¨
            cursor.execute('''
                           CREATE TABLE IF NOT EXISTS failed_records
                           (
                               url_path
                               TEXT
                               PRIMARY
                               KEY,
                               error_message
                               TEXT,
                               retry_count
                               INTEGER
                               DEFAULT
                               0,
                               last_attempt
                               TIMESTAMP
                               DEFAULT
                               CURRENT_TIMESTAMP
                           )
                           ''')

            conn.commit()
            logger.success(f"æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ: {self.db_path}")

        except Exception as e:
            logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        finally:
            if conn:
                conn.close()

    def insert_spider_record(self, url_path, status, error_msg=None):
        """å‘çˆ¬è™«è®°å½•è¡¨ä¸­æ’å…¥è®°å½•"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute("SELECT retry_count FROM propertyguru_spider WHERE url_path = ?", (url_path,))
            result = cursor.fetchone()
            retry_count = result[0] + 1 if result else 0

            cursor.execute('''
                INSERT OR REPLACE INTO propertyguru_spider 
                (url_path, status, retry_count, last_error, crawled_at) 
                VALUES (?, ?, ?, ?, ?)
            ''', (url_path, status, retry_count, error_msg, datetime.now()))

            conn.commit()
        except Exception as e:
            logger.error(f"çˆ¬è™«è®°å½•æ’å…¥å¤±è´¥: {url_path}, é”™è¯¯: {str(e)}")
        finally:
            if conn:
                conn.close()

    def check_spider_record(self, url_path, force_update=False):
        """æ£€æŸ¥çˆ¬è™«è®°å½•è¡¨ä¸­æ˜¯å¦å­˜åœ¨æˆåŠŸè®°å½•"""
        if force_update:
            return False  # å¼ºåˆ¶æ›´æ–°æ¨¡å¼ï¼Œè·³è¿‡æ£€æŸ¥

        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute(
                "SELECT status FROM propertyguru_spider WHERE url_path = ? AND status = 'å·²çˆ¬å–'",
                (url_path,)
            )
            result = cursor.fetchone()
            return result is not None
        except Exception as e:
            logger.error(f"æ£€æŸ¥çˆ¬è™«è®°å½•å¤±è´¥: {url_path}, é”™è¯¯: {str(e)}")
            return False
        finally:
            if conn:
                conn.close()

    def add_failed_record(self, url_path, error_msg):
        """æ·»åŠ å¤±è´¥è®°å½•"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute("SELECT retry_count FROM failed_records WHERE url_path = ?", (url_path,))
            result = cursor.fetchone()
            retry_count = result[0] + 1 if result else 1

            cursor.execute('''
                INSERT OR REPLACE INTO failed_records 
                (url_path, error_message, retry_count, last_attempt) 
                VALUES (?, ?, ?, ?)
            ''', (url_path, error_msg, retry_count, datetime.now()))

            conn.commit()
            logger.warning(f"æ·»åŠ å¤±è´¥è®°å½•: {url_path}, é‡è¯•æ¬¡æ•°: {retry_count}")
        except Exception as e:
            logger.error(f"æ·»åŠ å¤±è´¥è®°å½•å¤±è´¥: {str(e)}")
        finally:
            if conn:
                conn.close()

    def get_failed_records(self, max_retries=None):
        """è·å–éœ€è¦é‡è¯•çš„å¤±è´¥è®°å½•"""
        if max_retries is None:
            max_retries = self.MAX_RETRIES

        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute(
                "SELECT url_path FROM failed_records WHERE retry_count < ?",
                (max_retries,)
            )
            results = cursor.fetchall()
            return [row[0] for row in results]
        except Exception as e:
            logger.error(f"è·å–å¤±è´¥è®°å½•å¤±è´¥: {str(e)}")
            return []
        finally:
            if conn:
                conn.close()

    def insert_record(self, result):
        """å‘æ•°æ®åº“ä¸­æ’å…¥æˆ–æ›´æ–°è®°å½•"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            url_path = result.get("url_path", 'æ— url_path')

            cursor.execute("SELECT CEA, mobile, rating FROM propertyguru WHERE url_path = ?", (url_path,))
            existing = cursor.fetchone()

            if existing:
                # åªæ›´æ–°ä»£ç†ä¿¡æ¯å­—æ®µ
                cursor.execute('''
                               UPDATE propertyguru
                               SET CEA=?,
                                   mobile=?,
                                   rating=?,
                                   updated_at=?
                               WHERE url_path = ?
                               ''', (
                                   result.get("CEA", ''),
                                   result.get("mobile", ''),
                                   result.get("rating", ''),
                                   datetime.now(),
                                   url_path
                               ))
                logger.info(f"ä»£ç†ä¿¡æ¯æ›´æ–°æˆåŠŸ: {url_path}")
            else:
                # æ’å…¥å®Œæ•´è®°å½•
                cursor.execute('''
                               INSERT INTO propertyguru (ID, localizedTitle, fullAddress, price_pretty, beds, baths,
                                                         area_sqft, price_psf, nearbyText, built_year, property_type,
                                                         tenure, url_path, recency_text, agent_id, agent_name,
                                                         agent_description, agent_url_path, CEA, mobile, rating,
                                                         buy_rent)
                               VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                               ''', (
                                   result.get("ID", 'æ— id'),
                                   result.get("localizedTitle", 'æ— æ ‡é¢˜'),
                                   result.get("fullAddress", 'æ— åœ°å€'),
                                   result.get("price_pretty", 'æ— ä»·æ ¼'),
                                   result.get("beds", 'æ— åºŠæ•°'),
                                   result.get("baths", 'æ— æµ´å®¤æ•°'),
                                   result.get("area_sqft", 'æ— é¢ç§¯'),
                                   result.get("price_psf", 'æ— æ¯å¹³æ–¹è‹±å°ºä»·æ ¼'),
                                   result.get("nearbyText", 'æ— åœ°é“'),
                                   result.get("built_year", 'æ— å»ºé€ å¹´ä»½'),
                                   result.get("property_type", 'æ— ç‰©ä¸šç±»å‹'),
                                   result.get("tenure", 'æ— äº§æƒ'),
                                   url_path,
                                   result.get("recency_text", 'æ— æ›´æ–°æ—¶é—´'),
                                   result.get("agent_id", 'æ— id'),
                                   result.get("agent_name", 'æ— åå­—'),
                                   result.get("agent_description", 'æ— æè¿°'),
                                   result.get("agent_url_path", 'æ— url_path'),
                                   result.get("CEA", ''),
                                   result.get("mobile", ''),
                                   result.get("rating", ''),
                                   result.get("buy_rent", 'æ— buy_rent')
                               ))
                logger.info(f"è®°å½•æ’å…¥æˆåŠŸ: {url_path}")

            conn.commit()
            return True

        except Exception as e:
            logger.error(f"è®°å½•æ“ä½œå¤±è´¥: {url_path}, é”™è¯¯: {str(e)}")
            return False
        finally:
            if conn:
                conn.close()

    def check_record_exists(self, url_path):
        """æ£€æŸ¥ url è®°å½•æ˜¯å¦å­˜åœ¨"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT url_path FROM propertyguru WHERE url_path = ?", (url_path,))
            result = cursor.fetchone()
            return result is not None
        except Exception as e:
            logger.error(f"æ£€æŸ¥è®°å½•å¤±è´¥: {url_path}, é”™è¯¯: {str(e)}")
            return False
        finally:
            if conn:
                conn.close()

    def get_incomplete_records(self):
        """è·å–ä»£ç†ä¿¡æ¯ä¸å®Œæ•´çš„è®°å½•"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute('''
                           SELECT url_path
                           FROM propertyguru
                           WHERE (CEA IS NULL OR CEA = '' OR CEA = 'æ— CEA')
                              OR (mobile IS NULL OR mobile = '' OR mobile = 'æ— æ‰‹æœº')
                              OR (rating IS NULL OR rating = '' OR rating = 'æ— è¯„åˆ†')
                           ''')

            results = cursor.fetchall()
            url_paths = [row[0] for row in results]
            logger.info(f"æ‰¾åˆ° {len(url_paths)} æ¡ä»£ç†ä¿¡æ¯ä¸å®Œæ•´çš„è®°å½•")
            return url_paths

        except Exception as e:
            logger.error(f"è·å–ä¸å®Œæ•´è®°å½•å¤±è´¥: {str(e)}")
            return []
        finally:
            if conn:
                conn.close()

    def get_expired_records(self, days=None):
        """è·å–ä»£ç†ä¿¡æ¯è¿‡æœŸçš„è®°å½•ï¼ˆæ–°å¢ï¼‰"""
        if days is None:
            days = self.AGENT_INFO_EXPIRY_DAYS

        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            expiry_date = datetime.now() - timedelta(days=days)

            cursor.execute('''
                           SELECT url_path, updated_at
                           FROM propertyguru
                           WHERE updated_at < ?
                             AND CEA IS NOT NULL
                             AND CEA != '' AND CEA != 'æ— CEA'
                  AND mobile IS NOT NULL AND mobile != '' AND mobile != 'æ— æ‰‹æœº'
                  AND rating IS NOT NULL AND rating != '' AND rating != 'æ— è¯„åˆ†'
                           ''', (expiry_date,))

            results = cursor.fetchall()
            url_paths = [row[0] for row in results]

            if url_paths:
                logger.info(f"æ‰¾åˆ° {len(url_paths)} æ¡ä»£ç†ä¿¡æ¯å·²è¿‡æœŸçš„è®°å½•ï¼ˆè¶…è¿‡{days}å¤©æœªæ›´æ–°ï¼‰")
            else:
                logger.info(f"æ²¡æœ‰è¿‡æœŸçš„ä»£ç†ä¿¡æ¯ï¼ˆé˜ˆå€¼: {days}å¤©ï¼‰")

            return url_paths

        except Exception as e:
            logger.error(f"è·å–è¿‡æœŸè®°å½•å¤±è´¥: {str(e)}")
            return []
        finally:
            if conn:
                conn.close()

    def get_all_records(self):
        """è·å–æ‰€æœ‰è®°å½•ï¼ˆç”¨äºå…¨é‡æ›´æ–°ï¼‰"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute('SELECT url_path FROM propertyguru')
            results = cursor.fetchall()
            url_paths = [row[0] for row in results]

            logger.info(f"æ‰¾åˆ° {len(url_paths)} æ¡è®°å½•éœ€è¦æ›´æ–°ä»£ç†ä¿¡æ¯")
            return url_paths

        except Exception as e:
            logger.error(f"è·å–æ‰€æœ‰è®°å½•å¤±è´¥: {str(e)}")
            return []
        finally:
            if conn:
                conn.close()

    @func_set_timeout(60)
    def get_request(self, method, url, headers):
        return requests.request(method, url, headers=headers, verify=False)

    def fetch(self, url_path, max_try=2):
        """è¯·æ±‚ç½‘é¡µ"""
        for attempt in range(max_try):
            try:
                url = f"https://api.cloudbypass.com/{url_path}"
                method = "GET"
                headers = {
                    "x-cb-apikey": f"{self.apikey}",
                    "x-cb-host": r"www.propertyguru.com.sg",
                    "x-cb-version": r"2",
                    "x-cb-part": r"0",
                    "x-cb-fp": r"chrome",
                    "x-cb-proxy": f"{self.proxy}",
                }

                response = self.get_request(method, url, headers)

                if response and response.status_code == 200:
                    return response
                else:
                    logger.error(f"è¯·æ±‚å¤±è´¥ç¬¬ {attempt + 1} æ¬¡: {url_path}")
                    continue
            except Exception as e:
                logger.error(f"è¯·æ±‚å¼‚å¸¸ç¬¬ {attempt + 1} æ¬¡: {url_path} - {str(e)}")
                continue
        return None

    def get_property_detail(self, url_path):
        """è·å–è¯¦ç»†é¡µä»£ç†ä¿¡æ¯"""
        try:
            response = self.fetch(url_path)
            if not response:
                logger.error(f"è¯·æ±‚å¤±è´¥ï¼š{url_path}")
                return None

            file_name = url_path.replace('/', '_')
            with open(os.path.join(self.html_dir, f'detail_{file_name}.html'), 'w', encoding='utf-8') as f:
                f.write(response.text)

            data_json = re.findall('<script id="__NEXT_DATA__" type="application/json".*?>(.*?)</script>',
                                   response.text, re.S)
            if not data_json:
                logger.error(f"data_json è·å–å¤±è´¥ï¼š{url_path}")
                return None

            data_json = json.loads(data_json[0])

            with open(os.path.join(self.json_dir, f'detail_{file_name}.json'), 'w', encoding='utf-8') as f:
                json.dump(data_json, f, ensure_ascii=False, indent=4)

            agentInfoProps = data_json.get('props', {}).get('pageProps', {}).get('pageData', {}).get('data', {}).get(
                'contactAgentData', {}).get('contactAgentCard', {}).get("agentInfoProps", {})

            if not agentInfoProps:
                logger.warning(f"æœªæ‰¾åˆ°ä»£ç†ä¿¡æ¯: {url_path}")
                return {}

            agent = agentInfoProps.get('agent', {})
            description = re.sub(r'<[^>]*>', '', agent.get('description', 'æ— æè¿°'))
            mobile = agent.get('mobile', 'æ— æ‰‹æœº')

            rating = 'æ— è¯„åˆ†'
            rating_dic = agentInfoProps.get('rating', {})
            if rating_dic:
                rating = rating_dic.get('score', 'æ— è¯„åˆ†')

            dic = {
                "CEA": description,
                "mobile": mobile,
                "rating": rating
            }

            logger.info(f"æˆåŠŸè·å–ä»£ç†ä¿¡æ¯: {url_path}")
            return dic

        except Exception as e:
            logger.error(f"è·å–è¯¦ç»†é¡µå¤±è´¥: {url_path} - {str(e)}")
            return None

    def export_csv(self):
        """å¯¼å‡ºæ•°æ®åº“æ•°æ®åˆ°CSVæ–‡ä»¶"""
        try:
            export_dir = os.path.join(self.data_dir, "export")
            os.makedirs(export_dir, exist_ok=True)

            conn = sqlite3.connect(self.db_path)
            query = "SELECT * FROM propertyguru"
            df = pd.read_sql_query(query, conn)

            timestamp = time.strftime("%Y%m%d_%H%M%S")
            csv_path = os.path.join(export_dir, f"propertyguru_export_{timestamp}.csv")
            df.to_csv(csv_path, index=False, encoding='utf-8-sig')

            rent_df = df[df['buy_rent'] == 'property-for-rent']
            sale_df = df[df['buy_rent'] == 'property-for-sale']

            rent_csv_path = os.path.join(export_dir, f"propertyguru_rent_{timestamp}.csv")
            sale_csv_path = os.path.join(export_dir, f"propertyguru_sale_{timestamp}.csv")

            rent_df.to_csv(rent_csv_path, index=False, encoding='utf-8-sig')
            sale_df.to_csv(sale_csv_path, index=False, encoding='utf-8-sig')

            # ç»Ÿè®¡å®Œæ•´åº¦
            complete_records = len(df[
                                       (df['CEA'].notna()) & (df['CEA'] != '') & (df['CEA'] != 'æ— CEA') &
                                       (df['mobile'].notna()) & (df['mobile'] != '') & (df['mobile'] != 'æ— æ‰‹æœº') &
                                       (df['rating'].notna()) & (df['rating'] != '') & (df['rating'] != 'æ— è¯„åˆ†')
                                       ])

            stats = {
                "total_records": len(df),
                "rent_records": len(rent_df),
                "sale_records": len(sale_df),
                "complete_records": complete_records,
                "completion_rate": f"{complete_records / len(df) * 100:.2f}%" if len(df) > 0 else "0%",
                "export_time": timestamp
            }

            stats_path = os.path.join(export_dir, f"propertyguru_stats_{timestamp}.json")
            with open(stats_path, 'w', encoding='utf-8') as f:
                json.dump(stats, f, ensure_ascii=False, indent=4)

            logger.success(f"æ•°æ®å¯¼å‡ºæˆåŠŸ: {csv_path}")
            logger.success(f"ç§Ÿæˆ¿æ•°æ®: {rent_csv_path}, å…± {len(rent_df)} æ¡è®°å½•")
            logger.success(f"ä¹°æˆ¿æ•°æ®: {sale_csv_path}, å…± {len(sale_df)} æ¡è®°å½•")
            logger.success(f"å®Œæ•´è®°å½•: {complete_records}/{len(df)} ({stats['completion_rate']})")

            return csv_path

        except Exception as e:
            logger.error(f"å¯¼å‡ºCSVå¤±è´¥: {str(e)}")
            return None
        finally:
            if conn:
                conn.close()

    def process_records(self, url_paths, force_update=False):
        """é€šç”¨çš„è®°å½•å¤„ç†å‡½æ•°ï¼ˆæ–°å¢ï¼‰"""
        if not url_paths:
            logger.info("æ²¡æœ‰éœ€è¦å¤„ç†çš„è®°å½•")
            return

        total = len(url_paths)
        success = 0
        failed = 0
        skipped = 0

        logger.info(f"å¼€å§‹å¤„ç† {total} æ¡è®°å½•")

        for index, url_path in enumerate(url_paths, 1):
            # æ£€æŸ¥æ˜¯å¦å·²æˆåŠŸçˆ¬å–ï¼ˆå¼ºåˆ¶æ›´æ–°æ¨¡å¼ä¼šè·³è¿‡ï¼‰
            if not force_update and self.check_spider_record(url_path):
                logger.info(f"[{index}/{total}] å·²å¤„ç†: {url_path}")
                skipped += 1
                continue

            logger.info(f"[{index}/{total}] æ­£åœ¨å¤„ç†: {url_path}")

            # è·å–ä»£ç†ä¿¡æ¯
            agent_detail = self.get_property_detail(url_path)

            if not agent_detail:
                logger.error(f"è·å–ä»£ç†ä¿¡æ¯å¤±è´¥: {url_path}")
                self.add_failed_record(url_path, "è·å–ä»£ç†ä¿¡æ¯å¤±è´¥")
                self.insert_spider_record(url_path, 'å¤±è´¥', "è·å–ä»£ç†ä¿¡æ¯å¤±è´¥")
                failed += 1
                continue

            # æ›´æ–°è®°å½•
            dic = {
                "url_path": url_path,
                "CEA": agent_detail.get("CEA", ''),
                "mobile": agent_detail.get("mobile", ''),
                "rating": agent_detail.get("rating", '')
            }

            if self.insert_record(dic):
                self.insert_spider_record(url_path, 'å·²çˆ¬å–')
                success += 1
                logger.success(f"[{index}/{total}] å¤„ç†æˆåŠŸ: {url_path}")
            else:
                self.add_failed_record(url_path, "æ•°æ®åº“æ›´æ–°å¤±è´¥")
                failed += 1

            time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«

        logger.success(f"å¤„ç†å®Œæˆï¼æ€»æ•°: {total}, æˆåŠŸ: {success}, å¤±è´¥: {failed}, è·³è¿‡: {skipped}")

    def process_from_csv(self, csv_path):
        """ä»CSVæ–‡ä»¶ä¸­å¤„ç†æ•°æ®ï¼ˆä¿ç•™åŸæœ‰åŠŸèƒ½ï¼‰"""
        logger.info(f"ä»CSVæ–‡ä»¶è¯»å–æ•°æ®: {csv_path}")
        df = pd.read_csv(csv_path, dtype=str)

        total = len(df)
        processed = 0
        success = 0
        failed = 0

        for index, row in df.iterrows():
            url_path = row['url_path']

            if self.check_spider_record(url_path):
                logger.info(f"[{index + 1}/{total}] å·²å¤„ç†: {url_path}")
                processed += 1
                continue

            needs_update = (
                    pd.isna(row.get('CEA')) or row.get('CEA', '') in ['', 'æ— CEA'] or
                    pd.isna(row.get('mobile')) or row.get('mobile', '') in ['', 'æ— æ‰‹æœº'] or
                    pd.isna(row.get('rating')) or row.get('rating', '') in ['', 'æ— è¯„åˆ†']
            )

            if not needs_update:
                logger.info(f"[{index + 1}/{total}] ä»£ç†ä¿¡æ¯å®Œæ•´ï¼Œè·³è¿‡: {url_path}")
                processed += 1
                continue

            logger.info(f"[{index + 1}/{total}] æ­£åœ¨å¤„ç†: {url_path}")

            agent_detail = self.get_property_detail(url_path)

            if not agent_detail:
                logger.error(f"è·å–ä»£ç†ä¿¡æ¯å¤±è´¥: {url_path}")
                self.add_failed_record(url_path, "è·å–ä»£ç†ä¿¡æ¯å¤±è´¥")
                self.insert_spider_record(url_path, 'å¤±è´¥', "è·å–ä»£ç†ä¿¡æ¯å¤±è´¥")
                failed += 1
                continue

            dic = {
                'ID': row['ID'],
                "localizedTitle": row['localizedTitle'],
                "fullAddress": row['fullAddress'],
                "price_pretty": row['price_pretty'],
                "beds": row['beds'],
                "baths": row['baths'],
                "area_sqft": row['area_sqft'],
                "price_psf": row['price_psf'],
                "nearbyText": row['nearbyText'],
                "built_year": row['built_year'],
                "property_type": row['property_type'],
                "tenure": row['tenure'],
                "url_path": url_path,
                "recency_text": row['recency_text'],
                "agent_id": row['agent_id'],
                "agent_name": row['agent_name'],
                "agent_description": row['agent_description'],
                "agent_url_path": row['agent_url_path'],
                "CEA": agent_detail.get("CEA", ''),
                "mobile": agent_detail.get("mobile", ''),
                "rating": agent_detail.get("rating", ''),
                "buy_rent": row['buy_rent']
            }

            if self.insert_record(dic):
                self.insert_spider_record(url_path, 'å·²çˆ¬å–')
                success += 1
                logger.success(f"[{index + 1}/{total}] å¤„ç†æˆåŠŸ: {url_path}")
            else:
                self.add_failed_record(url_path, "æ•°æ®åº“æ’å…¥å¤±è´¥")
                failed += 1

            time.sleep(0.5)

        logger.success(f"å¤„ç†å®Œæˆï¼æ€»æ•°: {total}, æˆåŠŸ: {success}, å¤±è´¥: {failed}, è·³è¿‡: {processed}")

    def process_incomplete_records(self):
        """å¤„ç†ä»£ç†ä¿¡æ¯ä¸å®Œæ•´çš„è®°å½•"""
        url_paths = self.get_incomplete_records()
        self.process_records(url_paths, force_update=False)

    def process_expired_records(self, days=None):
        """å¤„ç†ä»£ç†ä¿¡æ¯è¿‡æœŸçš„è®°å½•ï¼ˆæ–°å¢ï¼‰"""
        url_paths = self.get_expired_records(days)
        if url_paths:
            logger.info(f"ğŸ”„ å¼€å§‹æ›´æ–°è¿‡æœŸçš„ä»£ç†ä¿¡æ¯")
            self.process_records(url_paths, force_update=True)

    def process_all_records(self):
        """å¼ºåˆ¶æ›´æ–°æ‰€æœ‰è®°å½•çš„ä»£ç†ä¿¡æ¯ï¼ˆæ–°å¢ï¼‰"""
        logger.warning("âš ï¸  å¼ºåˆ¶æ›´æ–°æ¨¡å¼ï¼šå°†é‡æ–°è·å–æ‰€æœ‰è®°å½•çš„ä»£ç†ä¿¡æ¯")
        url_paths = self.get_all_records()
        self.process_records(url_paths, force_update=True)

    def retry_failed_records(self, max_retries=None):
        """é‡è¯•å¤±è´¥çš„è®°å½•"""
        failed_urls = self.get_failed_records(max_retries)

        if not failed_urls:
            logger.info("æ²¡æœ‰éœ€è¦é‡è¯•çš„å¤±è´¥è®°å½•")
            return

        total = len(failed_urls)
        success = 0
        still_failed = 0

        logger.info(f"å¼€å§‹é‡è¯• {total} æ¡å¤±è´¥è®°å½•")

        for index, url_path in enumerate(failed_urls, 1):
            logger.info(f"[{index}/{total}] é‡è¯•: {url_path}")

            agent_detail = self.get_property_detail(url_path)

            if not agent_detail:
                logger.error(f"é‡è¯•å¤±è´¥: {url_path}")
                self.add_failed_record(url_path, "é‡è¯•ä»ç„¶å¤±è´¥")
                still_failed += 1
                continue

            dic = {
                "url_path": url_path,
                "CEA": agent_detail.get("CEA", ''),
                "mobile": agent_detail.get("mobile", ''),
                "rating": agent_detail.get("rating", '')
            }

            if self.insert_record(dic):
                self.insert_spider_record(url_path, 'å·²çˆ¬å–')
                # ä»å¤±è´¥è®°å½•è¡¨ä¸­åˆ é™¤
                try:
                    conn = sqlite3.connect(self.db_path)
                    cursor = conn.cursor()
                    cursor.execute("DELETE FROM failed_records WHERE url_path = ?", (url_path,))
                    conn.commit()
                    conn.close()
                except:
                    pass
                success += 1
                logger.success(f"[{index}/{total}] é‡è¯•æˆåŠŸ: {url_path}")
            else:
                self.add_failed_record(url_path, "é‡è¯•åæ•°æ®åº“æ›´æ–°å¤±è´¥")
                still_failed += 1

            time.sleep(0.5)

        logger.success(f"é‡è¯•å®Œæˆï¼æ€»æ•°: {total}, æˆåŠŸ: {success}, ä»å¤±è´¥: {still_failed}")

    def main(self, mode='incremental', csv_path=None, expiry_days=None):
        """
        ä¸»å‡½æ•°
        modeé€‰é¡¹ï¼š
        - 'incremental': å·®é‡æ›´æ–°ï¼ˆåªå¤„ç†ä¸å®Œæ•´çš„è®°å½•ï¼‰
        - 'expired': æ›´æ–°è¿‡æœŸçš„ä»£ç†ä¿¡æ¯ï¼ˆè¶…è¿‡æŒ‡å®šå¤©æ•°ï¼‰
        - 'full': å¼ºåˆ¶æ›´æ–°æ‰€æœ‰è®°å½•çš„ä»£ç†ä¿¡æ¯
        - 'csv': ä»CSVæ–‡ä»¶å¤„ç†
        - 'retry': é‡è¯•å¤±è´¥çš„è®°å½•

        å‚æ•°ï¼š
        - csv_path: å½“mode='csv'æ—¶éœ€è¦æä¾›CSVæ–‡ä»¶è·¯å¾„
        - expiry_days: å½“mode='expired'æ—¶æŒ‡å®šè¿‡æœŸå¤©æ•°ï¼ˆé»˜è®¤90å¤©ï¼‰
        """
        logger.info(f"ğŸš€ å¼€å§‹è¿è¡Œï¼Œæ¨¡å¼: {mode}")

        if mode == 'csv':
            if not csv_path:
                logger.error("CSVæ¨¡å¼éœ€è¦æä¾›csv_pathå‚æ•°")
                return
            self.process_from_csv(csv_path)

        elif mode == 'incremental':
            # å·®é‡æ›´æ–°ï¼šåªå¤„ç†ä»£ç†ä¿¡æ¯ä¸å®Œæ•´çš„è®°å½•
            logger.info("âš¡ å·®é‡æ›´æ–°ï¼šè¡¥å……ç¼ºå¤±çš„ä»£ç†ä¿¡æ¯")
            self.process_incomplete_records()

        elif mode == 'expired':
            # æ›´æ–°è¿‡æœŸè®°å½•ï¼šå¤„ç†è¶…è¿‡æŒ‡å®šå¤©æ•°æœªæ›´æ–°çš„è®°å½•
            days = expiry_days if expiry_days else self.AGENT_INFO_EXPIRY_DAYS
            logger.info(f"â° è¿‡æœŸæ›´æ–°ï¼šæ›´æ–°è¶…è¿‡{days}å¤©çš„ä»£ç†ä¿¡æ¯")
            self.process_expired_records(days)

        elif mode == 'full':
            # å…¨é‡æ›´æ–°ï¼šå¼ºåˆ¶é‡æ–°è·å–æ‰€æœ‰è®°å½•çš„ä»£ç†ä¿¡æ¯
            logger.warning("ğŸ”¥ å…¨é‡æ›´æ–°ï¼šé‡æ–°è·å–æ‰€æœ‰ä»£ç†ä¿¡æ¯ï¼ˆæ…ç”¨ï¼‰")
            self.process_all_records()

        elif mode == 'retry':
            # é‡è¯•å¤±è´¥çš„è®°å½•
            logger.info("ğŸ”„ é‡è¯•å¤±è´¥çš„è®°å½•")
            self.retry_failed_records()

        else:
            logger.error(f"æœªçŸ¥çš„æ¨¡å¼: {mode}")
            return

        # å¯¼å‡ºæ•°æ®åº“ä¸ºCSV
        self.export_csv()

        logger.success("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆ")


if __name__ == '__main__':
    pg = propertyguru()

    # æ¨¡å¼1ï¼šå·®é‡æ›´æ–°ï¼ˆæ¨èæ—¥å¸¸ä½¿ç”¨ï¼‰- åªè¡¥å……ç¼ºå¤±çš„ä»£ç†ä¿¡æ¯
    pg.main(mode='incremental')

    # æ¨¡å¼2ï¼šè¿‡æœŸæ›´æ–°ï¼ˆæ¨èå®šæœŸè¿è¡Œï¼‰- æ›´æ–°è¶…è¿‡90å¤©çš„ä»£ç†ä¿¡æ¯
    # pg.main(mode='expired', expiry_days=90)

    # æ¨¡å¼3ï¼šå…¨é‡æ›´æ–°ï¼ˆæ…ç”¨ï¼‰- é‡æ–°è·å–æ‰€æœ‰ä»£ç†ä¿¡æ¯
    # pg.main(mode='full')

    # æ¨¡å¼4ï¼šä»CSVæ–‡ä»¶å¤„ç†
    # pg.main(mode='csv', csv_path=r'data\export\propertyguru_export_20250903_220506.csv')

    # æ¨¡å¼5ï¼šé‡è¯•å¤±è´¥çš„è®°å½•
    # pg.main(mode='retry')