2025-10-28 16:32:30 [scrapy.utils.log] INFO: Scrapy 2.13.3 started (bot: property_scraper)
2025-10-28 16:32:30 [scrapy.utils.log] INFO: Versions:
{'lxml': '6.0.2',
 'libxml2': '2.14.6',
 'cssselect': '1.3.0',
 'parsel': '1.10.0',
 'w3lib': '2.3.1',
 'Twisted': '25.5.0',
 'Python': '3.9.13 (v3.9.13:6de2ca5339, May 17 2022, 11:37:23) - [Clang 13.0.0 '
           '(clang-1300.0.29.30)]',
 'pyOpenSSL': '25.3.0 (OpenSSL 3.5.4 30 Sep 2025)',
 'cryptography': '46.0.3',
 'Platform': 'macOS-26.0.1-arm64-arm-64bit'}
2025-10-28 16:32:30 [scrapy.addons] INFO: Enabled addons:
[]
2025-10-28 16:32:30 [asyncio] DEBUG: Using selector: KqueueSelector
2025-10-28 16:32:30 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-10-28 16:32:30 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-10-28 16:32:30 [scrapy.extensions.telnet] INFO: Telnet Password: d279d9d415b7b7fd
2025-10-28 16:32:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-10-28 16:32:30 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'property_scraper',
 'CONCURRENT_REQUESTS': 5,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 1,
 'DOWNLOAD_DELAY': 1,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_propertyguru.log',
 'NEWSPIDER_MODULE': 'property_scraper.spiders',
 'RETRY_TIMES': 3,
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['property_scraper.spiders']}
2025-10-28 16:32:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-10-28 16:32:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.start.StartSpiderMiddleware',
 'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-10-28 16:32:30 [twisted] CRITICAL: Unhandled error in Deferred:
2025-10-28 16:32:30 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/Users/alanwang/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1857, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/alanwang/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/scrapy/crawler.py", line 156, in crawl
    self.engine = self._create_engine()
  File "/Users/alanwang/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/scrapy/crawler.py", line 169, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/Users/alanwang/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/scrapy/core/engine.py", line 114, in __init__
    self.scraper: Scraper = Scraper(crawler)
  File "/Users/alanwang/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/scrapy/core/scraper.py", line 107, in __init__
    self.itemproc: ItemPipelineManager = itemproc_cls.from_crawler(crawler)
  File "/Users/alanwang/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/scrapy/middleware.py", line 77, in from_crawler
    return cls._from_settings(crawler.settings, crawler)
  File "/Users/alanwang/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/scrapy/middleware.py", line 86, in _from_settings
    mwcls = load_object(clspath)
  File "/Users/alanwang/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/scrapy/utils/misc.py", line 71, in load_object
    mod = import_module(module)
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/Users/alanwang/PycharmProjects/PythonProject/property_scraper/property_scraper/pipelines.py", line 13, in <module>
    from models import Listing
  File "/Users/alanwang/PycharmProjects/PythonProject/property_aggregator/models.py", line 6, in <module>
    from .database import Base
ImportError: attempted relative import with no known parent package
2025-10-28 16:33:14 [scrapy.utils.log] INFO: Scrapy 2.13.3 started (bot: property_scraper)
2025-10-28 16:33:14 [scrapy.utils.log] INFO: Versions:
{'lxml': '6.0.2',
 'libxml2': '2.14.6',
 'cssselect': '1.3.0',
 'parsel': '1.10.0',
 'w3lib': '2.3.1',
 'Twisted': '25.5.0',
 'Python': '3.9.13 (v3.9.13:6de2ca5339, May 17 2022, 11:37:23) - [Clang 13.0.0 '
           '(clang-1300.0.29.30)]',
 'pyOpenSSL': '25.3.0 (OpenSSL 3.5.4 30 Sep 2025)',
 'cryptography': '46.0.3',
 'Platform': 'macOS-26.0.1-arm64-arm-64bit'}
2025-10-28 16:33:14 [scrapy.addons] INFO: Enabled addons:
[]
2025-10-28 16:33:14 [asyncio] DEBUG: Using selector: KqueueSelector
2025-10-28 16:33:14 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-10-28 16:33:14 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-10-28 16:33:14 [scrapy.extensions.telnet] INFO: Telnet Password: a30cc0086d08d16e
2025-10-28 16:33:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-10-28 16:33:14 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'property_scraper',
 'CONCURRENT_REQUESTS': 5,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 1,
 'DOWNLOAD_DELAY': 1,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_propertyguru.log',
 'NEWSPIDER_MODULE': 'property_scraper.spiders',
 'RETRY_TIMES': 3,
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['property_scraper.spiders']}
2025-10-28 16:33:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-10-28 16:33:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.start.StartSpiderMiddleware',
 'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-10-28 16:33:14 [twisted] CRITICAL: Unhandled error in Deferred:
2025-10-28 16:33:14 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/Users/alanwang/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1857, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/alanwang/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/scrapy/crawler.py", line 156, in crawl
    self.engine = self._create_engine()
  File "/Users/alanwang/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/scrapy/crawler.py", line 169, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/Users/alanwang/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/scrapy/core/engine.py", line 114, in __init__
    self.scraper: Scraper = Scraper(crawler)
  File "/Users/alanwang/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/scrapy/core/scraper.py", line 107, in __init__
    self.itemproc: ItemPipelineManager = itemproc_cls.from_crawler(crawler)
  File "/Users/alanwang/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/scrapy/middleware.py", line 77, in from_crawler
    return cls._from_settings(crawler.settings, crawler)
  File "/Users/alanwang/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/scrapy/middleware.py", line 86, in _from_settings
    mwcls = load_object(clspath)
  File "/Users/alanwang/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/scrapy/utils/misc.py", line 71, in load_object
    mod = import_module(module)
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/Users/alanwang/PycharmProjects/PythonProject/property_scraper/property_scraper/pipelines.py", line 12, in <module>
    from property_aggregator.database import engine, SessionLocal
ModuleNotFoundError: No module named 'property_aggregator'
2025-10-28 16:33:49 [scrapy.utils.log] INFO: Scrapy 2.13.3 started (bot: property_scraper)
2025-10-28 16:33:49 [scrapy.utils.log] INFO: Versions:
{'lxml': '6.0.2',
 'libxml2': '2.14.6',
 'cssselect': '1.3.0',
 'parsel': '1.10.0',
 'w3lib': '2.3.1',
 'Twisted': '25.5.0',
 'Python': '3.9.13 (v3.9.13:6de2ca5339, May 17 2022, 11:37:23) - [Clang 13.0.0 '
           '(clang-1300.0.29.30)]',
 'pyOpenSSL': '25.3.0 (OpenSSL 3.5.4 30 Sep 2025)',
 'cryptography': '46.0.3',
 'Platform': 'macOS-26.0.1-arm64-arm-64bit'}
2025-10-28 16:33:49 [scrapy.addons] INFO: Enabled addons:
[]
2025-10-28 16:33:49 [asyncio] DEBUG: Using selector: KqueueSelector
2025-10-28 16:33:49 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-10-28 16:33:49 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-10-28 16:33:49 [scrapy.extensions.telnet] INFO: Telnet Password: e5e06238c56d7b4c
2025-10-28 16:33:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-10-28 16:33:49 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'property_scraper',
 'CONCURRENT_REQUESTS': 5,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 1,
 'DOWNLOAD_DELAY': 1,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_propertyguru.log',
 'NEWSPIDER_MODULE': 'property_scraper.spiders',
 'RETRY_TIMES': 3,
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['property_scraper.spiders']}
2025-10-28 16:33:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-10-28 16:33:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.start.StartSpiderMiddleware',
 'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-10-28 16:33:49 [scrapy.middleware] INFO: Enabled item pipelines:
['property_scraper.pipelines.PostgreSQLPipeline']
2025-10-28 16:33:49 [scrapy.core.engine] INFO: Spider opened
2025-10-28 16:33:49 [py.warnings] WARNING: /Users/alanwang/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py:433: ScrapyDeprecationWarning: property_scraper.spiders.propertyguru_spider.PropertyGuruSpider defines the deprecated start_requests() method. start_requests() has been deprecated in favor of a new method, start(), to support asynchronous code execution. start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace start_requests() with start(); note that start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when overriding start_requests() in a spider class, override start() as well; you can use super() to reuse the inherited start() implementation without copy-pasting. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html
  warn(

2025-10-28 16:33:49 [propertyguru] INFO: Pipeline: 正在打开数据库会话。
2025-10-28 16:33:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-10-28 16:33:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-10-28 16:33:49 [scrapy-playwright] INFO: Starting download handler
2025-10-28 16:33:49 [scrapy-playwright] INFO: Starting download handler
2025-10-28 16:33:50 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): publicsuffix.org:443
2025-10-28 16:33:50 [urllib3.connectionpool] DEBUG: https://publicsuffix.org:443 "GET /list/public_suffix_list.dat HTTP/1.1" 200 88322
2025-10-28 16:33:50 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://www.propertyguru.com.sg/robots.txt> (referer: None)
2025-10-28 16:33:50 [protego._protego] DEBUG: Rule at line 1 without any user agent to enforce it on.
2025-10-28 16:33:51 [scrapy-playwright] INFO: Launching browser chromium
2025-10-28 16:33:53 [scrapy-playwright] INFO: Browser chromium launched
2025-10-28 16:33:53 [scrapy-playwright] DEBUG: Browser context started: 'default' (persistent=False, remote=False)
2025-10-28 16:33:54 [scrapy-playwright] DEBUG: [Context=default] New page created, page count is 1 (1 for all contexts)
2025-10-28 16:33:54 [scrapy-playwright] DEBUG: [Context=default] Request: <GET https://www.propertyguru.com.sg/property-for-rent> (resource type: document)
2025-10-28 16:33:54 [scrapy-playwright] DEBUG: [Context=default] Response: <307 https://www.propertyguru.com.sg/property-for-rent> (location: https://www.propertyguru.com.sg/property-for-rent)
2025-10-28 16:33:54 [scrapy-playwright] DEBUG: [Context=default] Request: <GET https://www.propertyguru.com.sg/property-for-rent> (resource type: document)
2025-10-28 16:33:54 [scrapy-playwright] DEBUG: [Context=default] Response: <403 https://www.propertyguru.com.sg/property-for-rent>
2025-10-28 16:33:54 [scrapy-playwright] DEBUG: [Context=default] Request: <GET https://www.propertyguru.com.sg/cdn-cgi/challenge-platform/h/b/orchestrate/chl_page/v1?ray=9959174be93cf88e> (resource type: script, referrer: https://www.propertyguru.com.sg/property-for-rent?__cf_chl_rt_tk=BWo3FrXauYrPh2wJdbNbu7flBr14voa0RxAyVVE3mCs-1761640434-1.0.1.1-bjsiyvnu_0N6NIo4h5qhQhk3ECIyl2PkT9r6cEfrW0E)
2025-10-28 16:33:54 [scrapy-playwright] DEBUG: [Context=default] Response: <200 https://www.propertyguru.com.sg/cdn-cgi/challenge-platform/h/b/orchestrate/chl_page/v1?ray=9959174be93cf88e>
2025-10-28 16:33:54 [scrapy-playwright] DEBUG: [Context=default] Request: <GET https://challenges.cloudflare.com/turnstile/v0/b/c88755b0cddc/api.js?onload=tJNc6&render=explicit> (resource type: script)
2025-10-28 16:33:54 [scrapy-playwright] DEBUG: [Context=default] Request: <POST https://www.propertyguru.com.sg/cdn-cgi/challenge-platform/h/b/flow/ov1/105593104:1761638818:bZGbqz34PXnlg9sqVuTmLSyeXmE1B0CVBWscTwtBoKo/9959174be93cf88e/uqjMdOPCty3.erQy2qTSQibsjv9bPXz69hXDTALW2Uo-1761640434-1.2.1.1-7ZCaH2o1jsBZ0C5RvXP2ERbVa7_BVHzkjBSygg.0IJ7xlocZmUZQix.sO9qDG.4Z> (resource type: xhr, referrer: https://www.propertyguru.com.sg/property-for-rent)
2025-10-28 16:33:54 [scrapy-playwright] DEBUG: [Context=default] Response: <200 https://challenges.cloudflare.com/turnstile/v0/b/c88755b0cddc/api.js?onload=tJNc6&render=explicit>
2025-10-28 16:33:54 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://www.propertyguru.com.sg/property-for-rent> (referer: None) ['playwright']
2025-10-28 16:33:54 [scrapy-playwright] DEBUG: [Context=default] New page created, page count is 1 (1 for all contexts)
2025-10-28 16:33:54 [scrapy-playwright] DEBUG: [Context=default] Request: <GET https://www.propertyguru.com.sg/property-for-sale> (resource type: document)
2025-10-28 16:33:54 [scrapy-playwright] DEBUG: [Context=default] Response: <403 https://www.propertyguru.com.sg/property-for-sale>
2025-10-28 16:33:54 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://www.propertyguru.com.sg/property-for-rent>: HTTP status code is not handled or not allowed
2025-10-28 16:33:54 [scrapy-playwright] DEBUG: [Context=default] Request: <GET https://www.propertyguru.com.sg/cdn-cgi/challenge-platform/h/b/orchestrate/chl_page/v1?ray=9959174eb83af88e> (resource type: script, referrer: https://www.propertyguru.com.sg/property-for-sale?__cf_chl_rt_tk=GXSa6I5u493g6eanWvy03FYPsjm2L8_vgYQ_6AJ3OPA-1761640435-1.0.1.1-8mQneceUvo_LBKwSz9J77NrUiquTFGXLGJtF1OXavbY)
2025-10-28 16:33:55 [scrapy-playwright] DEBUG: [Context=default] Response: <200 https://www.propertyguru.com.sg/cdn-cgi/challenge-platform/h/b/orchestrate/chl_page/v1?ray=9959174eb83af88e>
2025-10-28 16:33:55 [scrapy-playwright] DEBUG: [Context=default] Request: <GET https://challenges.cloudflare.com/turnstile/v0/b/c88755b0cddc/api.js?onload=tJNc6&render=explicit> (resource type: script)
2025-10-28 16:33:55 [scrapy-playwright] DEBUG: [Context=default] Response: <200 https://challenges.cloudflare.com/turnstile/v0/b/c88755b0cddc/api.js?onload=tJNc6&render=explicit>
2025-10-28 16:33:55 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://www.propertyguru.com.sg/property-for-sale> (referer: None) ['playwright']
2025-10-28 16:33:55 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://www.propertyguru.com.sg/property-for-sale>: HTTP status code is not handled or not allowed
2025-10-28 16:33:55 [scrapy.core.engine] INFO: Closing spider (finished)
2025-10-28 16:33:55 [propertyguru] INFO: Pipeline: 正在关闭数据库会话。
2025-10-28 16:33:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1191,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 46757,
 'downloader/response_count': 3,
 'downloader/response_status_count/403': 3,
 'elapsed_time_seconds': 5.295394,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 10, 28, 8, 33, 55, 216191, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 9023,
 'httpcompression/response_count': 1,
 'httperror/response_ignored_count': 2,
 'httperror/response_ignored_status_count/403': 2,
 'items_per_minute': 0.0,
 'log_count/DEBUG': 27,
 'log_count/INFO': 18,
 'log_count/WARNING': 1,
 'memusage/max': 93536256,
 'memusage/startup': 93536256,
 'playwright/browser_count': 1,
 'playwright/context_count': 1,
 'playwright/context_count/max_concurrent': 1,
 'playwright/context_count/persistent/False': 1,
 'playwright/context_count/remote/False': 1,
 'playwright/page_count': 2,
 'playwright/page_count/closed': 2,
 'playwright/page_count/max_concurrent': 1,
 'playwright/request_count': 8,
 'playwright/request_count/method/GET': 7,
 'playwright/request_count/method/POST': 1,
 'playwright/request_count/navigation': 3,
 'playwright/request_count/resource_type/document': 3,
 'playwright/request_count/resource_type/script': 4,
 'playwright/request_count/resource_type/xhr': 1,
 'playwright/response_count': 7,
 'playwright/response_count/method/GET': 7,
 'playwright/response_count/resource_type/document': 3,
 'playwright/response_count/resource_type/script': 4,
 'response_received_count': 3,
 'responses_per_minute': 36.0,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/403': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2025, 10, 28, 8, 33, 49, 920797, tzinfo=datetime.timezone.utc)}
2025-10-28 16:33:55 [scrapy.core.engine] INFO: Spider closed (finished)
2025-10-28 16:33:55 [scrapy-playwright] INFO: Closing download handler
2025-10-28 16:33:55 [scrapy-playwright] INFO: Closing download handler
2025-10-28 16:33:55 [scrapy-playwright] DEBUG: Browser context closed: 'default' (persistent=False, remote=False)
2025-10-28 16:33:55 [scrapy-playwright] INFO: Closing browser
2025-10-28 16:33:55 [scrapy-playwright] DEBUG: Browser disconnected
2025-10-28 16:42:05 [scrapy.utils.log] INFO: Scrapy 2.13.3 started (bot: property_scraper)
2025-10-28 16:42:05 [scrapy.utils.log] INFO: Versions:
{'lxml': '6.0.2',
 'libxml2': '2.14.6',
 'cssselect': '1.3.0',
 'parsel': '1.10.0',
 'w3lib': '2.3.1',
 'Twisted': '25.5.0',
 'Python': '3.9.13 (v3.9.13:6de2ca5339, May 17 2022, 11:37:23) - [Clang 13.0.0 '
           '(clang-1300.0.29.30)]',
 'pyOpenSSL': '25.3.0 (OpenSSL 3.5.4 30 Sep 2025)',
 'cryptography': '46.0.3',
 'Platform': 'macOS-26.0.1-arm64-arm-64bit'}
2025-10-28 16:42:05 [twisted] CRITICAL: Unhandled error in Deferred:
2025-10-28 16:42:05 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/Users/alanwang/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1857, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/alanwang/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/scrapy/crawler.py", line 153, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/Users/alanwang/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/scrapy/crawler.py", line 166, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/Users/alanwang/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/scrapy/spiders/__init__.py", line 74, in from_crawler
    spider = cls(*args, **kwargs)
  File "/Users/alanwang/PycharmProjects/PythonProject/property_scraper/property_scraper/spiders/propertyguru_spider.py", line 29, in __init__
    self.APIKEY = self.settings.get('CLOUDBYPASS_APIKEY', '')
AttributeError: 'PropertyGuruSpider' object has no attribute 'settings'
2025-10-28 16:44:04 [scrapy.utils.log] INFO: Scrapy 2.13.3 started (bot: property_scraper)
2025-10-28 16:44:04 [scrapy.utils.log] INFO: Versions:
{'lxml': '6.0.2',
 'libxml2': '2.14.6',
 'cssselect': '1.3.0',
 'parsel': '1.10.0',
 'w3lib': '2.3.1',
 'Twisted': '25.5.0',
 'Python': '3.9.13 (v3.9.13:6de2ca5339, May 17 2022, 11:37:23) - [Clang 13.0.0 '
           '(clang-1300.0.29.30)]',
 'pyOpenSSL': '25.3.0 (OpenSSL 3.5.4 30 Sep 2025)',
 'cryptography': '46.0.3',
 'Platform': 'macOS-26.0.1-arm64-arm-64bit'}
2025-10-28 16:44:04 [scrapy.addons] INFO: Enabled addons:
[]
2025-10-28 16:44:04 [asyncio] DEBUG: Using selector: KqueueSelector
2025-10-28 16:44:04 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-10-28 16:44:04 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-10-28 16:44:04 [scrapy.extensions.telnet] INFO: Telnet Password: a11c265ae47c06db
2025-10-28 16:44:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-10-28 16:44:04 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'property_scraper',
 'CONCURRENT_REQUESTS': 5,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 1,
 'DOWNLOAD_DELAY': 1,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_propertyguru.log',
 'NEWSPIDER_MODULE': 'property_scraper.spiders',
 'RETRY_TIMES': 3,
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['property_scraper.spiders']}
2025-10-28 16:44:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-10-28 16:44:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.start.StartSpiderMiddleware',
 'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-10-28 16:44:04 [scrapy.middleware] INFO: Enabled item pipelines:
['property_scraper.pipelines.PostgreSQLPipeline']
2025-10-28 16:44:04 [scrapy.core.engine] INFO: Spider opened
2025-10-28 16:44:04 [py.warnings] WARNING: /Users/alanwang/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py:433: ScrapyDeprecationWarning: property_scraper.spiders.propertyguru_spider.PropertyGuruSpider defines the deprecated start_requests() method. start_requests() has been deprecated in favor of a new method, start(), to support asynchronous code execution. start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace start_requests() with start(); note that start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when overriding start_requests() in a spider class, override start() as well; you can use super() to reuse the inherited start() implementation without copy-pasting. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html
  warn(

2025-10-28 16:44:04 [propertyguru] INFO: Pipeline: 正在打开数据库会话。
2025-10-28 16:44:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-10-28 16:44:04 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-10-28 16:44:04 [scrapy-playwright] INFO: Starting download handler
2025-10-28 16:44:04 [scrapy-playwright] INFO: Starting download handler
2025-10-28 16:44:05 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://www.propertyguru.com.sg/robots.txt> (referer: None)
2025-10-28 16:44:05 [protego._protego] DEBUG: Rule at line 1 without any user agent to enforce it on.
2025-10-28 16:44:06 [scrapy-playwright] INFO: Launching browser chromium
2025-10-28 16:44:06 [scrapy-playwright] INFO: Browser chromium launched
2025-10-28 16:44:06 [scrapy-playwright] DEBUG: Browser context started: 'default' (persistent=False, remote=False)
2025-10-28 16:44:06 [scrapy-playwright] DEBUG: [Context=default] New page created, page count is 1 (1 for all contexts)
2025-10-28 16:44:06 [scrapy-playwright] DEBUG: [Context=default] Request: <GET https://www.propertyguru.com.sg/property-for-rent> (resource type: document)
2025-10-28 16:44:06 [scrapy-playwright] DEBUG: [Context=default] Response: <307 https://www.propertyguru.com.sg/property-for-rent> (location: https://www.propertyguru.com.sg/property-for-rent)
2025-10-28 16:44:06 [scrapy-playwright] DEBUG: [Context=default] Request: <GET https://www.propertyguru.com.sg/property-for-rent> (resource type: document)
2025-10-28 16:44:06 [scrapy-playwright] DEBUG: [Context=default] Response: <403 https://www.propertyguru.com.sg/property-for-rent>
2025-10-28 16:44:07 [scrapy-playwright] DEBUG: [Context=default] Request: <GET https://www.propertyguru.com.sg/cdn-cgi/challenge-platform/h/b/orchestrate/chl_page/v1?ray=9959263fee025f37> (resource type: script, referrer: https://www.propertyguru.com.sg/property-for-rent?__cf_chl_rt_tk=8bKp_JyLNF1u.GgwwMPgLJuSS5gL9Z.DeUW1qUud8Jg-1761641047-1.0.1.1-v019FoilfQtOgUUpdbxUdILh8KNVgzeuedEpENXnSGg)
2025-10-28 16:44:07 [scrapy-playwright] DEBUG: [Context=default] Response: <200 https://www.propertyguru.com.sg/cdn-cgi/challenge-platform/h/b/orchestrate/chl_page/v1?ray=9959263fee025f37>
2025-10-28 16:44:07 [scrapy-playwright] DEBUG: [Context=default] Request: <GET https://challenges.cloudflare.com/turnstile/v0/b/c88755b0cddc/api.js?onload=tJNc6&render=explicit> (resource type: script)
2025-10-28 16:44:07 [scrapy-playwright] DEBUG: [Context=default] Request: <POST https://www.propertyguru.com.sg/cdn-cgi/challenge-platform/h/b/flow/ov1/105593104:1761638818:bZGbqz34PXnlg9sqVuTmLSyeXmE1B0CVBWscTwtBoKo/9959263fee025f37/eM9BmMx6yNiugcdN74rExpLVBK7F.VhOQ7UKSRmTzkc-1761641047-1.2.1.1-kCgg5hH7OJODfrbCEUxgeZnQQYICS7sJwTAleklUwi0FAJXDDk9kVlOKZUHjdKY7> (resource type: xhr, referrer: https://www.propertyguru.com.sg/property-for-rent)
2025-10-28 16:44:07 [scrapy-playwright] DEBUG: [Context=default] Response: <200 https://challenges.cloudflare.com/turnstile/v0/b/c88755b0cddc/api.js?onload=tJNc6&render=explicit>
2025-10-28 16:44:07 [scrapy-playwright] DEBUG: [Context=default] Response: <200 https://www.propertyguru.com.sg/cdn-cgi/challenge-platform/h/b/flow/ov1/105593104:1761638818:bZGbqz34PXnlg9sqVuTmLSyeXmE1B0CVBWscTwtBoKo/9959263fee025f37/eM9BmMx6yNiugcdN74rExpLVBK7F.VhOQ7UKSRmTzkc-1761641047-1.2.1.1-kCgg5hH7OJODfrbCEUxgeZnQQYICS7sJwTAleklUwi0FAJXDDk9kVlOKZUHjdKY7>
2025-10-28 16:44:07 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://www.propertyguru.com.sg/property-for-rent> (referer: None) ['playwright']
2025-10-28 16:44:07 [scrapy-playwright] DEBUG: [Context=default] Request: <GET https://challenges.cloudflare.com/cdn-cgi/challenge-platform/h/b/turnstile/f/ov2/av0/rch/zvpdu/0x4AAAAAAADnPIDROrmt1Wwj/light/fbE/new/normal?lang=auto> (resource type: document)
2025-10-28 16:44:07 [propertyguru] ERROR: __NEXT_DATA__ JSON not found on https://www.propertyguru.com.sg/property-for-rent
2025-10-28 16:44:07 [scrapy-playwright] DEBUG: [Context=default] New page created, page count is 1 (1 for all contexts)
2025-10-28 16:44:07 [scrapy-playwright] DEBUG: [Context=default] Request: <GET https://www.propertyguru.com.sg/property-for-sale> (resource type: document)
2025-10-28 16:44:07 [scrapy-playwright] DEBUG: [Context=default] Response: <403 https://www.propertyguru.com.sg/property-for-sale>
2025-10-28 16:44:07 [scrapy-playwright] DEBUG: [Context=default] Request: <GET https://www.propertyguru.com.sg/cdn-cgi/challenge-platform/h/b/orchestrate/chl_page/v1?ray=9959264378a15f37> (resource type: script, referrer: https://www.propertyguru.com.sg/property-for-sale?__cf_chl_rt_tk=CYIpo7kOt_CcuHyKfmH9l8UOX31YUQJVj.X91yU9GLo-1761641047-1.0.1.1-EJvGok2IoSks85QStRx52oZf_UypVmE224l7XJajjdE)
2025-10-28 16:44:07 [scrapy-playwright] DEBUG: [Context=default] Response: <200 https://www.propertyguru.com.sg/cdn-cgi/challenge-platform/h/b/orchestrate/chl_page/v1?ray=9959264378a15f37>
2025-10-28 16:44:07 [scrapy-playwright] DEBUG: [Context=default] Request: <GET https://challenges.cloudflare.com/turnstile/v0/b/c88755b0cddc/api.js?onload=tJNc6&render=explicit> (resource type: script)
2025-10-28 16:44:07 [scrapy-playwright] DEBUG: [Context=default] Response: <200 https://challenges.cloudflare.com/turnstile/v0/b/c88755b0cddc/api.js?onload=tJNc6&render=explicit>
2025-10-28 16:44:07 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://www.propertyguru.com.sg/property-for-sale> (referer: None) ['playwright']
2025-10-28 16:44:07 [propertyguru] ERROR: __NEXT_DATA__ JSON not found on https://www.propertyguru.com.sg/property-for-sale
2025-10-28 16:44:07 [scrapy.core.engine] INFO: Closing spider (finished)
2025-10-28 16:44:07 [propertyguru] INFO: Pipeline: 正在关闭数据库会话。
2025-10-28 16:44:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1434,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 46921,
 'downloader/response_count': 3,
 'downloader/response_status_count/403': 3,
 'elapsed_time_seconds': 3.100623,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 10, 28, 8, 44, 7, 863468, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 9044,
 'httpcompression/response_count': 1,
 'items_per_minute': 0.0,
 'log_count/DEBUG': 27,
 'log_count/ERROR': 2,
 'log_count/INFO': 16,
 'log_count/WARNING': 1,
 'memusage/max': 94535680,
 'memusage/startup': 94535680,
 'playwright/browser_count': 1,
 'playwright/context_count': 1,
 'playwright/context_count/max_concurrent': 1,
 'playwright/context_count/persistent/False': 1,
 'playwright/context_count/remote/False': 1,
 'playwright/page_count': 2,
 'playwright/page_count/closed': 2,
 'playwright/page_count/max_concurrent': 1,
 'playwright/request_count': 9,
 'playwright/request_count/method/GET': 8,
 'playwright/request_count/method/POST': 1,
 'playwright/request_count/navigation': 4,
 'playwright/request_count/resource_type/document': 4,
 'playwright/request_count/resource_type/script': 4,
 'playwright/request_count/resource_type/xhr': 1,
 'playwright/response_count': 8,
 'playwright/response_count/method/GET': 7,
 'playwright/response_count/method/POST': 1,
 'playwright/response_count/resource_type/document': 3,
 'playwright/response_count/resource_type/script': 4,
 'playwright/response_count/resource_type/xhr': 1,
 'response_received_count': 3,
 'responses_per_minute': 60.0,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/403': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2025, 10, 28, 8, 44, 4, 762845, tzinfo=datetime.timezone.utc)}
2025-10-28 16:44:07 [scrapy.core.engine] INFO: Spider closed (finished)
2025-10-28 16:44:07 [scrapy-playwright] INFO: Closing download handler
2025-10-28 16:44:07 [scrapy-playwright] INFO: Closing download handler
2025-10-28 16:44:07 [scrapy-playwright] DEBUG: Browser context closed: 'default' (persistent=False, remote=False)
2025-10-28 16:44:07 [scrapy-playwright] INFO: Closing browser
2025-10-28 16:44:07 [scrapy-playwright] DEBUG: Browser disconnected
